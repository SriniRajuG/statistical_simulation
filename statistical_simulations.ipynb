{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import statsmodels.api as sm\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Basics"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Poisson random variable\n",
    "\n",
    "- Using `np.random.poisson()` draw samples from a Poisson distribution using `lam` (lambda) and `size_1`.\n",
    "- Repeat the above step, but this time use `size_2`.\n",
    "- For each of the above samples, calculate the absolute difference between their mean and lambda"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "|Lambda - sample mean| with 3 samples is 0.33333333333333304 and with 1000 samples is 0.07699999999999996. \n"
     ]
    }
   ],
   "source": [
    "np.random.seed(123) \n",
    "lam, size_1, size_2 = 5, 3, 1000  \n",
    "\n",
    "# Draw samples \n",
    "samples_1 = np.random.poisson(lam, size_1)\n",
    "samples_2 = np.random.poisson(lam, size_2)\n",
    "# Calculate absolute difference between lambda and sample mean\n",
    "answer_1 = abs(lam - samples_1.mean())\n",
    "answer_2 = abs(lam - samples_2.mean()) \n",
    "\n",
    "print(\"|Lambda - sample mean| with {} samples is {} and with {} samples is {}. \".format(size_1, answer_1, size_2, answer_2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Shuffling a deck of cards\n",
    "\n",
    "\n",
    "- Use the `np.random.shuffle()` function to shuffle deck_of_cards."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('Heart', 0), ('Heart', 1), ('Heart', 2), ('Heart', 3), ('Heart', 4), ('Heart', 5), ('Heart', 6), ('Heart', 7), ('Heart', 8), ('Heart', 9), ('Heart', 10), ('Heart', 11), ('Heart', 12), ('Club', 0), ('Club', 1), ('Club', 2), ('Club', 3), ('Club', 4), ('Club', 5), ('Club', 6), ('Club', 7), ('Club', 8), ('Club', 9), ('Club', 10), ('Club', 11), ('Club', 12), ('Spade', 0), ('Spade', 1), ('Spade', 2), ('Spade', 3), ('Spade', 4), ('Spade', 5), ('Spade', 6), ('Spade', 7), ('Spade', 8), ('Spade', 9), ('Spade', 10), ('Spade', 11), ('Spade', 12), ('Diamond', 0), ('Diamond', 1), ('Diamond', 2), ('Diamond', 3), ('Diamond', 4), ('Diamond', 5), ('Diamond', 6), ('Diamond', 7), ('Diamond', 8), ('Diamond', 9), ('Diamond', 10), ('Diamond', 11), ('Diamond', 12)]\n",
      "\n",
      "Top three cards of the deck.\n",
      "[('Spade', 2), ('Heart', 5), ('Spade', 9)]\n"
     ]
    }
   ],
   "source": [
    "suits = ['Heart', 'Club', 'Spade', 'Diamond']\n",
    "ranks = list(range(0, 13))\n",
    "\n",
    "deck_of_cards = list()\n",
    "for suit in suits:\n",
    "    for rank in ranks:\n",
    "        deck_of_cards.append((suit, rank))\n",
    "        \n",
    "print(deck_of_cards)\n",
    "print()\n",
    "\n",
    "np.random.shuffle(deck_of_cards)\n",
    "\n",
    "# Print top 3 cards\n",
    "print(f'Top three cards of the deck.')\n",
    "print(deck_of_cards[:3])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Simulating dice game\n",
    "\n",
    "Throw two fair dice and if the number on both the dice are the same, we win. \n",
    "\n",
    "Simulation steps:\n",
    "1. Define possible outcomes for random variables.\n",
    "2. Assign probabilities.\n",
    "3. Define relationships between random variables.\n",
    "4. Get multiple outcomes by repeated random sampling.\n",
    "5. Analyze sample outcomes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "In 100 games, you win 14 times\n"
     ]
    }
   ],
   "source": [
    "np.random.seed(123)\n",
    "\n",
    "# Define die outcomes and probabilities\n",
    "die = np.arange(1, 7)\n",
    "probabilities = np.repeat((1 / 6), 6)\n",
    "throws = 2\n",
    "\n",
    "n_simulations = 100\n",
    "n_wins = 0\n",
    "\n",
    "for idx_sim in range(n_simulations):\n",
    "    # Use np.random.choice to throw the die once and record the outcome\n",
    "    outcomes = np.random.choice(die, size=throws, p=probabilities)\n",
    "    # Win if the two dice show the same number\n",
    "    if outcomes[0] == outcomes[1]:\n",
    "        n_wins += 1\n",
    "        \n",
    "print(f\"In {n_simulations} games, you win {n_wins} times\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Simulating lottery win\n",
    "\n",
    "We will use simulations to figure out whether or not we want to buy a lottery ticket. Suppose you have the opportunity to buy a lottery ticket which gives you a shot at a grand prize of \\\\$1 Million. There are a total of 1000 tickets. Each ticket costs \\\\$10. \n",
    "\n",
    "What should the price of the ticket be for us to but the ticket and make positive payoff."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average payoff from 20000 simulations = 990.0\n"
     ]
    }
   ],
   "source": [
    "np.random.seed(123)\n",
    "\n",
    "# Initialize size and simulate outcome\n",
    "lottery_ticket_cost, num_tickets, grand_prize = 10, 1000, 1000000\n",
    "chance_of_winning = 1 / num_tickets\n",
    "n_sims = 20000\n",
    "payoffs = [-lottery_ticket_cost, grand_prize - lottery_ticket_cost]\n",
    "probs = [1 - chance_of_winning, chance_of_winning]\n",
    "\n",
    "outcomes = np.random.choice(a=payoffs, size=n_sims, p=probs, replace=True)\n",
    "\n",
    "# Mean of outcomes.\n",
    "avg_payoff = outcomes.mean()\n",
    "print(f\"Average payoff from {n_sims} simulations = {avg_payoff}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The highest price at which it makes sense to buy the ticket is 535\n"
     ]
    }
   ],
   "source": [
    "sims, lottery_ticket_cost = 20000, 0\n",
    "\n",
    "while 1:\n",
    "    outcomes = np.random.choice(\n",
    "        [-lottery_ticket_cost, grand_prize-lottery_ticket_cost],\n",
    "        size=sims, \n",
    "        p=[1-chance_of_winning, chance_of_winning], \n",
    "        replace=True\n",
    "    )\n",
    "    if outcomes.mean() < 0:\n",
    "        break\n",
    "    else:\n",
    "        lottery_ticket_cost += 1\n",
    "answer = lottery_ticket_cost - 1\n",
    "\n",
    "print(\"The highest price at which it makes sense to buy the ticket is {}\".format(answer))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Consider a deck of cards (13 cards x 4 suites = 52 cards in total). One card is drawn at random. What is the probability of getting a queen or a spade?\n",
    "\n",
    "16/52  \n",
    "P(A∪B)=P(A)+P(B)−P(A∩B)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Probability of win in Poker\n",
    "\n",
    "Suppose you've been invited to a game of poker at your friend's home. In this variation of the game, you are dealt five cards and the player with the better hand wins. Estimate the probability of getting at least two of a kind. Two of a kind is when you get two cards of different suites but having the same numeric value (e.g., 2 of hearts, 2 of spades, and 3 other cards)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Probability of seeing at least two of a kind = 0.4975 \n"
     ]
    }
   ],
   "source": [
    "suits = ['Heart', 'Club', 'Spade', 'Diamond']\n",
    "ranks = list(range(0, 13))\n",
    "\n",
    "deck_of_cards = list()\n",
    "for suit in suits:\n",
    "    for rank in ranks:\n",
    "        deck_of_cards.append((suit, rank))\n",
    "\n",
    "# Shuffle deck & count card occurrences in the hand\n",
    "n_sims, two_kind = 10000, 0\n",
    "for idx_sim in range(n_sims):\n",
    "    np.random.shuffle(deck_of_cards)\n",
    "    hand = deck_of_cards[0:5]\n",
    "    cards_in_hand = dict()\n",
    "    for card in hand:\n",
    "        # Count the no. of cards with same rank\n",
    "        cards_in_hand[card[1]] = cards_in_hand.get(card[1], 0) + 1\n",
    "    \n",
    "    # Condition for getting at least 2 of a kind\n",
    "    max_n_cards_same_rank = max(cards_in_hand.values())\n",
    "    if max_n_cards_same_rank >= 2: \n",
    "        two_kind += 1\n",
    "\n",
    "print(\"Probability of seeing at least two of a kind = {} \".format(two_kind/n_sims))\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Game of thirteen\n",
    "\n",
    "A famous French mathematician Pierre Raymond De Montmart, who was known for his work in combinatorics, proposed a simple game called as Game of Thirteen. You have a deck of 13 cards, each numbered from 1 through 13. Shuffle this deck and draw cards one by one. A coincidence is when the number on the card matches the order in which the card is drawn. For instance, if the 5th card you draw happens to be a 5, it's a coincidence. You win the game if you get through all the cards without any coincidences. Let's calculate the probability of winning at this game using simulation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Probaility of a win in game of 13 is 0.3633\n"
     ]
    }
   ],
   "source": [
    "deck = np.arange(1, 14)\n",
    "n_wins = 0\n",
    "n_sims = 10000\n",
    "\n",
    "for _ in range(n_sims): \n",
    "    n_coincidences = 0\n",
    "    np.random.shuffle(deck)\n",
    "    for idx, rank in enumerate(deck):\n",
    "        if idx + 1 == rank:\n",
    "            n_coincidences += 1\n",
    "    if n_coincidences == 0:\n",
    "        n_wins += 1\n",
    "    \n",
    "print(f'Probaility of a win in game of 13 is {n_wins / n_sims}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Conditional Probability"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## The conditional urn\n",
    "\n",
    "We have an urn that contains 7 white and 6 black balls. Four balls are drawn at random. We'd like to know the probability that the first and third balls are white, while the second and the fourth balls are black. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Probability of success = 0.0772\n"
     ]
    }
   ],
   "source": [
    "success, sims = 0, 5000\n",
    "urn = (['w'] * 7) + (['b'] * 6)\n",
    "\n",
    "for _ in range(sims):\n",
    "    # Draw 4 balls without replacement\n",
    "    draw = np.random.choice(urn, replace=False, size=4)\n",
    "    # Count the number of successes\n",
    "    if draw[0] == 'w' and draw[2] == 'w' and draw[1] == 'b' and draw[3] == 'b': \n",
    "        success +=1\n",
    "\n",
    "print(\"Probability of success = {}\".format(success/sims))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Birthday problem\n",
    "\n",
    "How many people do you need in a room to ensure at least a 50% chance that two of them share the same birthday?\n",
    "With 366 people in a 365-day year, we are 100% sure that at least two have the same birthday, but we only need to be 50% sure."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def birthday_sim(n_people):\n",
    "    n_sims= 10000\n",
    "    n_success = 0 \n",
    "    for _ in range(n_sims):\n",
    "        birthdays = np.random.choice(days, size=n_people, replace=True)\n",
    "        if len(birthdays) > len(set(birthdays)): \n",
    "            # Success if two people have the same birthday\n",
    "            n_success += 1\n",
    "    prob_success = n_success / n_sims\n",
    "    return prob_success"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.4139"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "days = np.arange(1, 366)\n",
    "n_people = 20\n",
    "prob_success = birthday_sim(n_people)\n",
    "prob_success"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "With 23 people, there's a 50% chance that two share a birthday.\n"
     ]
    }
   ],
   "source": [
    "n_people = 0\n",
    "while True:\n",
    "    n_people += 1\n",
    "    prob_success = birthday_sim(n_people)\n",
    "    if prob_success >= 0.5:\n",
    "        break\n",
    "print(f\"With {n_people} people, there's a 50% chance that two share a birthday.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Full house\n",
    "\n",
    "A full house is when you get two cards of different suits that share the same numeric value and three other cards that have the same numeric value (e.g., 2 of hearts & spades, jacks of clubs, diamonds, & spades). Thus, a full house is the probability of getting exactly three of a kind conditional on getting exactly two of a kind of another value. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Probability of seeing a full house = 0.00162\n"
     ]
    }
   ],
   "source": [
    "suits = ['Heart', 'Club', 'Spade', 'Diamond']\n",
    "ranks = list(range(0, 13))\n",
    "\n",
    "deck_of_cards = list()\n",
    "for suit in suits:\n",
    "    for rank in ranks:\n",
    "        deck_of_cards.append((suit, rank))\n",
    "\n",
    "#Shuffle deck & count card occurrences in the hand\n",
    "n_sims, full_house = 50000, 0\n",
    "for i in range(n_sims):\n",
    "    np.random.shuffle(deck_of_cards)\n",
    "    hand, cards_in_hand = deck_of_cards[0:5], {}\n",
    "    for card in hand:\n",
    "        # Use .get() method to count occurrences of each card\n",
    "        cards_in_hand[card[1]] = cards_in_hand.get(card[1], 0) + 1\n",
    "        \n",
    "    # Condition for getting full house\n",
    "    condition = (max(cards_in_hand.values()) == 3) & (min(cards_in_hand.values()) == 2)\n",
    "    if  condition == True: \n",
    "        full_house += 1\n",
    "print(f\"Probability of seeing a full house = {full_house / n_sims}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Generation Process"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Driving test\n",
    "\n",
    "Suppose that you are about to take a driving test tomorrow. Based on your own practice and based on data you have gathered, you know that the probability of you passing the test is 90% when it's sunny and only 30% when it's raining. Your local weather station forecasts that there's a 40% chance of rain tomorrow. Based on this information, you want to know what is the probability of you passing the driving test tomorrow."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.651039\n"
     ]
    }
   ],
   "source": [
    "n_pass = 0\n",
    "n_sims_w = 500\n",
    "n_sims_t = 500\n",
    "\n",
    "for _ in range(n_sims_w):\n",
    "    weather = np.random.choice(['sunny', 'rainy'], p=[0.6, 0.4])\n",
    "    for _ in range(n_sims_t):\n",
    "        if weather == 'sunny':\n",
    "            result = np.random.choice(['pass', 'fail'], p=[0.9, 0.1])\n",
    "            if result == 'pass':\n",
    "                n_pass += 1\n",
    "        if weather == 'rainy':\n",
    "            result = np.random.choice(['pass', 'fail'], p=[0.3, 0.7])\n",
    "            if result == 'pass':\n",
    "                n_pass += 1\n",
    "\n",
    "print(n_pass / (n_sims_w * n_sims_t))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## National elections\n",
    "\n",
    "Consider national elections in a country with two political parties - Red and Blue. This country has 50 states and the party that wins the most states wins the elections. You have the probability p of Red winning in each individual state and want to know the probability of Red winning nationally.\n",
    "\n",
    "Suppose the election outcome in each state follows a binomial distribution with probability p such that 0 indicates a loss for Red and 1 indicates a win. What is the probability of Red winning less than 45% of the states?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Probbaility of Red party winning in the 50 states. Given as input. \n",
    "# For this exercise, random numbers could also have been used.\n",
    "\n",
    "p = np.array(\n",
    "    [0.52076814, 0.67846401, 0.82731745, 0.64722761, 0.03665174,\n",
    "    0.17835411, 0.75296372, 0.22206157, 0.72778372, 0.28461556,\n",
    "    0.72545221, 0.106571  , 0.09291364, 0.77535718, 0.51440142,\n",
    "    0.89604586, 0.39376099, 0.24910244, 0.92518253, 0.08165597,\n",
    "    0.4212476 , 0.74123879, 0.2479099 , 0.46125805, 0.19584491,\n",
    "    0.24440482, 0.349916  , 0.80224624, 0.80186664, 0.82968251,\n",
    "    0.91178779, 0.51739059, 0.67338858, 0.15675863, 0.37772308,\n",
    "    0.77134621, 0.71727114, 0.92700912, 0.28386132, 0.25502498,\n",
    "    0.30081506, 0.19724585, 0.29129564, 0.56623386, 0.97681039,\n",
    "    0.96263926, 0.0548948 , 0.14092758, 0.54739446, 0.54555576]\n",
    ")\n",
    "n_states = p.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "outcomes, sims, probs = [], 1000, p\n",
    "\n",
    "for _ in range(sims):\n",
    "    # Simulate elections in the 50 states\n",
    "    election = np.random.binomial(n=1, p=p)\n",
    "    # Get average of Red wins and add to `outcomes`\n",
    "    outcomes.append(election.sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Probability of Red part winning less than 45% of the states is 0.204\n"
     ]
    }
   ],
   "source": [
    "cutoff_wins = 0.45 * n_states\n",
    "prob_wins = np.array([outcome < cutoff_wins for outcome in outcomes]).sum() / len(outcomes)\n",
    "print(f'Probability of Red part winning less than 45% of the states is {prob_wins}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Fitness goals\n",
    "\n",
    "Let's model how activity levels impact weight loss using modern fitness trackers. On days when you go to the gym, you average around 15k steps, and around 5k steps otherwise. You go to the gym 40% of the time. Let's model the step counts in a day as a Poisson random variable with a mean λ dependent on whether or not you go to the gym.\n",
    "\n",
    "For simplicity, let’s say you have an 80% chance of losing 1lb and a 20% chance of gaining 1lb when you get more than 10k steps. The probabilities are reversed when you get less than 8k steps. Otherwise, there's an even chance of gaining or losing 1lb. Given all this information, find the probability of losing weight in a month"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.233\n"
     ]
    }
   ],
   "source": [
    "n_sims = 1000\n",
    "n_days = 30\n",
    "prob_gym = 0.4\n",
    "lam_gym = 15\n",
    "lam_no_gym = 5\n",
    "\n",
    "weight = np.zeros(n_sims)\n",
    "for idx_sim in range(n_sims):\n",
    "    for idx_days in range(n_days):\n",
    "        activity = np.random.choice(a=['gym', 'no_gym'], p=[prob_gym, 1 - prob_gym])\n",
    "        if activity == 'gym':\n",
    "            n_steps = np.random.poisson(lam=lam_gym)\n",
    "        else:\n",
    "            n_steps = np.random.poisson(lam=lam_no_gym)\n",
    "        if n_steps > 10:\n",
    "            weight[idx_sim] += np.random.choice(a=[-1, 1], p=[.8, .2])\n",
    "        elif n_steps < 8:\n",
    "            weight[idx_sim] += np.random.choice(a=[-1, 1], p=[.2, .8])\n",
    "        else:\n",
    "            weight[idx_sim] += np.random.choice(a=[-1, 1], p=[.5, .5])\n",
    "\n",
    "print(np.sum(weight < 0) / n_sims)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## E-Commerce funnel\n",
    "\n",
    "Ad-impressions ---> clicks ---> signup ---> purchase ---> purchase-value\n",
    "\n",
    "\n",
    "(poisson)         (binomial)   (binomial)  (binomial)     (exponential)\n",
    "\n",
    "\n",
    "- click-through-rate is parameter for binomail dist. of clicks  \n",
    "- signup-rate is parameter of binomial dist. of signups  \n",
    "- purchase-rate is the parameter of binomial dist of purchases.  \n",
    "- Avg. purchase value is parameter of exponential dist. of purchase value."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Sign up Flow**\n",
    "\n",
    "We will now model the data generation process (DGP) of an eCommerce ad flow starting with sign-ups.\n",
    "\n",
    "On any day, we get many ad impressions, which can be modeled as Poisson random variables (RV). You are told that λ is normally distributed with a mean of 100k visitors and standard deviation 2000.\n",
    "\n",
    "During the signup journey, the customer sees an ad, decides whether or not to click, and then whether or not to signup. Thus both clicks and signups are binary, modeled using binomial RVs. What about probability p\n",
    "of success? Our current low-cost option gives us a click-through rate of 1% and a sign-up rate of 20%. A higher cost option could increase the clickthrough and signup rate by up to 20%, but we are unsure of the level of improvement, so we model it as a uniform RV."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Simulated Signups = [221]\n"
     ]
    }
   ],
   "source": [
    "# Initialize click-through rate and signup rate\n",
    "ct_rate = {'low':0.01, 'high':np.random.uniform(low=0.01, high=1.2*0.01)}\n",
    "su_rate = {'low':0.2, 'high':np.random.uniform(low=0.2, high=1.2*0.2)}\n",
    "\n",
    "def get_signups(cost, ct_rate, su_rate, sims):\n",
    "    lam = np.random.normal(loc=100000, scale=2000, size=sims)\n",
    "    # Simulate impressions(poisson), clicks(binomial) and signups(binomial)\n",
    "    impressions = np.random.poisson(lam=lam)\n",
    "    clicks = np.random.binomial(n=impressions, p=ct_rate[cost])\n",
    "    signups = np.random.binomial(n=clicks, p=su_rate[cost])\n",
    "    return signups\n",
    "\n",
    "print(\"Simulated Signups = {}\".format(get_signups('high', ct_rate, su_rate, 1)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Purchase Flow**\n",
    "\n",
    "After signups, let's model the revenue generation process. Once the customer has signed up, they decide whether or not to purchase - a natural candidate for a binomial RV. Let's assume that 10% of signups result in a purchase.\n",
    "\n",
    "Although customers can make many purchases, let's assume one purchase. The purchase value could be modeled by any continuous RV, but one nice candidate is the exponential RV. Suppose we know that purchase value per customer has averaged around \\\\$1000. We use this information to create the purchase_values RV. The revenue, then, is simply the sum of all purchase values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Simulated Revenue = $19788.227707152106\n"
     ]
    }
   ],
   "source": [
    "def get_revenue(signups):\n",
    "    rev = []\n",
    "    np.random.seed(123)\n",
    "    for s in signups:\n",
    "        # Model purchases as binomial, purchase_values as exponential\n",
    "        purchases = np.random.binomial(s, p=0.1)\n",
    "        # purchase_values could be modeled as normal dist as well.\n",
    "        purchase_values = np.random.exponential(scale=1000, size=purchases)\n",
    "        \n",
    "        # Append to revenue the sum of all purchase values.\n",
    "        rev.append(sum(purchase_values))\n",
    "    return rev\n",
    "\n",
    "print(\"Simulated Revenue = ${}\".format(get_revenue(get_signups('low', ct_rate, su_rate, 1))[0]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Probability of losing money**\n",
    "\n",
    "As seen earlier, this company has the option of spending extra money, let's say \\\\$3000, to redesign the ad. This could potentially get them higher clickthrough and signup rates, but this is not guaranteed. We would like to know whether or not to spend this extra $3000 by calculating the probability of losing money. In other words, the probability that the revenue from the high-cost option minus the revenue from the low-cost option is lesser than the cost."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "probability of loosing money on increasing ad spending is 0.5901\n"
     ]
    }
   ],
   "source": [
    "# Initialize cost_diff\n",
    "sims, cost_diff = 10000, 3000\n",
    "\n",
    "# Get revenue when the cost is 'low' and when the cost is 'high'\n",
    "rev_low = get_revenue(get_signups('low', ct_rate, su_rate, sims))\n",
    "rev_high = get_revenue(get_signups('high', ct_rate, su_rate, sims))\n",
    "\n",
    "rev_diff = np.array(rev_high) - np.array(rev_low)\n",
    "frac_loss = np.sum(rev_diff < cost_diff) / sims\n",
    "print(f'probability of loosing money on increasing ad spending is {frac_loss}') "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Resampling "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Lets review the difference between sampling with and without replacement.  \n",
    "Consider a bowl filled with colored candies - three blue, two green, and five yellow. Draw three candies at random, with replacement and without replacement. You want to know the probability of drawing a yellow candy on the third draw given that the first candy was blue and the second candy was green."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Probability with replacement = 0.0317, without replacement = 0.0415\n"
     ]
    }
   ],
   "source": [
    "# Set up the bowl\n",
    "success_rep, success_no_rep, sims = 0, 0, 10000\n",
    "bowl = ['b'] * 3 + ['g'] * 2 + ['y'] * 5\n",
    "\n",
    "for i in range(sims):\n",
    "    # Sample with and without replacement & increment success counters\n",
    "    sample_rep = np.random.choice(bowl, size=3, replace=True)\n",
    "    sample_no_rep = np.random.choice(bowl, size=3, replace=False)\n",
    "    if (sample_rep[0] == 'b') & (sample_rep[1] == 'g') & (sample_rep[2] == 'y'): \n",
    "        success_rep += 1\n",
    "    if (sample_no_rep[0] == 'b') & (sample_no_rep[1] == 'g') & (sample_no_rep[2] == 'y'): \n",
    "        success_no_rep += 1\n",
    "\n",
    "# Calculate probabilities\n",
    "prob_with_replacement = success_rep / sims\n",
    "prob_without_replacement = success_no_rep /sims\n",
    "print(\"Probability with replacement = {}, without replacement = {}\".format(prob_with_replacement, prob_without_replacement))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Bootstraping"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Suppose you own a factory that produces wrenches. You want to be able to characterize the average length of the wrenches and ensure that they meet some specifications. Your factory produces thousands of wrenches every day, but it's infeasible to measure the length of each wrench. However, you have access to a representative sample of 100 wrenches. Let's use bootstrapping to get the 95% confidence interval (CI) for the average lengths."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bootstrapped Mean Length = 10.026530828306102, 95% CI = [ 9.79993508 10.25614254]\n"
     ]
    }
   ],
   "source": [
    "wrench_lengths = np.array([ \n",
    "       8.9143694 , 10.99734545, 10.2829785 ,  8.49370529,  9.42139975,\n",
    "       11.65143654,  7.57332076,  9.57108737, 11.26593626,  9.1332596 ,\n",
    "        9.32111385,  9.90529103, 11.49138963,  9.361098  ,  9.55601804,\n",
    "        9.56564872, 12.20593008, 12.18678609, 11.0040539 , 10.3861864 ,\n",
    "       10.73736858, 11.49073203,  9.06416613, 11.17582904,  8.74611933,\n",
    "        9.3622485 , 10.9071052 ,  8.5713193 ,  9.85993128,  9.1382451 ,\n",
    "        9.74438063,  7.20141089,  8.2284669 ,  9.30012277, 10.92746243,\n",
    "        9.82636432, 10.00284592, 10.68822271,  9.12046366, 10.28362732,\n",
    "        9.19463348,  8.27233051,  9.60910021, 10.57380586, 10.33858905,\n",
    "        9.98816951, 12.39236527, 10.41291216, 10.97873601, 12.23814334,\n",
    "        8.70591468,  8.96121179, 11.74371223,  9.20193726, 10.02968323,\n",
    "       11.06931597, 10.89070639, 11.75488618, 11.49564414, 11.06939267,\n",
    "        9.22729129, 10.79486267, 10.31427199,  8.67373454, 11.41729905,\n",
    "       10.80723653, 10.04549008,  9.76690794,  8.80169886, 10.19952407,\n",
    "       10.46843912,  9.16884502, 11.16220405,  8.90279695,  7.87689965,\n",
    "       11.03972709,  9.59663396,  9.87397041,  9.16248328,  8.39403724,\n",
    "       11.25523737,  9.31113102, 11.66095249, 10.80730819,  9.68524185,\n",
    "        8.9140976 ,  9.26753801,  8.78747687, 12.08711336, 10.16444123,\n",
    "       11.15020554,  8.73264795, 10.18103513, 11.17786194,  9.66498924,\n",
    "       11.03111446,  8.91543209,  8.63652846, 10.37940061,  9.62082357\n",
    "])\n",
    "\n",
    "# Draw some random sample with replacement and append mean to mean_lengths.\n",
    "mean_lengths, sims = [], 1000\n",
    "for i in range(sims):\n",
    "    temp_sample = np.random.choice(wrench_lengths, replace=True, size=wrench_lengths.shape[0])\n",
    "    sample_mean = temp_sample.mean()\n",
    "    mean_lengths.append(sample_mean)\n",
    "    \n",
    "# Calculate bootstrapped mean and 95% confidence interval.\n",
    "boot_mean = np.mean(mean_lengths)\n",
    "boot_95_ci = np.percentile(mean_lengths, [2.5, 97.5])\n",
    "print(\"Bootstrapped Mean Length = {}, 95% CI = {}\".format(boot_mean, boot_95_ci))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Suppose you are studying the health of students. You are given the height and weight of 1000 students and are interested in the median height as well as the correlation between height and weight and the associated 95% CI for these quantities. Let's use bootstrapping."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "heights = np.random.normal(loc=170, scale=7, size=1000)  # in centimeters\n",
    "weights = np.random.normal(loc=60, scale=4, size=1000)  # in Kg\n",
    "\n",
    "df = pd.DataFrame(data={'heights': heights, 'weights': weights})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>heights</th>\n",
       "      <th>weights</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>174.394336</td>\n",
       "      <td>59.579711</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>166.965237</td>\n",
       "      <td>57.592754</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>173.567983</td>\n",
       "      <td>60.675014</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>158.970455</td>\n",
       "      <td>57.096213</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>166.362096</td>\n",
       "      <td>63.816117</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      heights    weights\n",
       "0  174.394336  59.579711\n",
       "1  166.965237  57.592754\n",
       "2  173.567983  60.675014\n",
       "3  158.970455  57.096213\n",
       "4  166.362096  63.816117"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Height Median CI = [169.40555047 170.45873501] \n",
      "Height Weight Correlation CI = [-0.06814172  0.05295427]\n"
     ]
    }
   ],
   "source": [
    "# Sample with replacement and calculate quantities of interest\n",
    "sims, data_size, height_medians, hw_corr = 1000, df.shape[0], [], []\n",
    "for i in range(sims):\n",
    "    tmp_df = df.sample(n=df.shape[0], replace=True)\n",
    "    height_medians.append(tmp_df['heights'].median())\n",
    "    hw_corr.append(tmp_df.corr().loc['heights', 'weights'])\n",
    "\n",
    "# Calculate confidence intervals\n",
    "height_median_ci = np.percentile(height_medians, [2.5, 97.5])\n",
    "height_weight_corr_ci = np.percentile(hw_corr, [2.5, 97.5])\n",
    "print(\"Height Median CI = {} \\nHeight Weight Correlation CI = {}\".format( height_median_ci, height_weight_corr_ci))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Bootstrapping regression**\n",
    "\n",
    "Bootstrapping helps estimate the uncertainty of non-standard estimators. Consider the R2 statistic associated with a regression. When you run a simple least squares regression, you get a value for R2. But let's see how can we get a 95% CI for R2."
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "rsquared_boot, coefs_boot, sims = [], [], 1000\n",
    "reg_fit = sm.OLS(df['y'], df.iloc[:,1:]).fit()\n",
    "\n",
    "# Run 1K iterations\n",
    "for i in range(sims):\n",
    "    # First create a bootstrap sample with replacement with n=df.shape[0]\n",
    "    bootstrap = df.sample(n=df.shape[0], replace=True)\n",
    "    # Fit the regression and append the r square to rsquared_boot\n",
    "    rsquared_boot.append(sm.OLS(bootstrap['y'],bootstrap.iloc[:,1:]).fit().rsquared)\n",
    "\n",
    "# Calculate 95% CI on rsquared_boot\n",
    "r_sq_95_ci = np.percentile(rsquared_boot, [2.5, 97.5])\n",
    "print(\"R Squared 95% CI = {}\".format(r_sq_95_ci))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Jackknife Resampling\n",
    "\n",
    "https://en.wikipedia.org/wiki/Jackknife_resampling  \n",
    "https://www.datasciencecentral.com/profiles/blogs/resampling-methods-comparison"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Estimate the mean length of wrenches."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Jackknife estimate of the mean = 10.027109074099998\n"
     ]
    }
   ],
   "source": [
    "wrench_lengths = np.array([ \n",
    "       8.9143694 , 10.99734545, 10.2829785 ,  8.49370529,  9.42139975,\n",
    "       11.65143654,  7.57332076,  9.57108737, 11.26593626,  9.1332596 ,\n",
    "        9.32111385,  9.90529103, 11.49138963,  9.361098  ,  9.55601804,\n",
    "        9.56564872, 12.20593008, 12.18678609, 11.0040539 , 10.3861864 ,\n",
    "       10.73736858, 11.49073203,  9.06416613, 11.17582904,  8.74611933,\n",
    "        9.3622485 , 10.9071052 ,  8.5713193 ,  9.85993128,  9.1382451 ,\n",
    "        9.74438063,  7.20141089,  8.2284669 ,  9.30012277, 10.92746243,\n",
    "        9.82636432, 10.00284592, 10.68822271,  9.12046366, 10.28362732,\n",
    "        9.19463348,  8.27233051,  9.60910021, 10.57380586, 10.33858905,\n",
    "        9.98816951, 12.39236527, 10.41291216, 10.97873601, 12.23814334,\n",
    "        8.70591468,  8.96121179, 11.74371223,  9.20193726, 10.02968323,\n",
    "       11.06931597, 10.89070639, 11.75488618, 11.49564414, 11.06939267,\n",
    "        9.22729129, 10.79486267, 10.31427199,  8.67373454, 11.41729905,\n",
    "       10.80723653, 10.04549008,  9.76690794,  8.80169886, 10.19952407,\n",
    "       10.46843912,  9.16884502, 11.16220405,  8.90279695,  7.87689965,\n",
    "       11.03972709,  9.59663396,  9.87397041,  9.16248328,  8.39403724,\n",
    "       11.25523737,  9.31113102, 11.66095249, 10.80730819,  9.68524185,\n",
    "        8.9140976 ,  9.26753801,  8.78747687, 12.08711336, 10.16444123,\n",
    "       11.15020554,  8.73264795, 10.18103513, 11.17786194,  9.66498924,\n",
    "       11.03111446,  8.91543209,  8.63652846, 10.37940061,  9.62082357\n",
    "])\n",
    "\n",
    "# Leave one observation out from wrench_lengths to get the jackknife sample and store the mean length\n",
    "mean_lengths = list()\n",
    "n = len(wrench_lengths)\n",
    "index = np.arange(n)\n",
    "\n",
    "for i in range(n):\n",
    "    jk_sample = wrench_lengths[index != i]\n",
    "    mean_lengths.append(jk_sample.mean())\n",
    "\n",
    "# The jackknife estimate is the mean of the mean lengths from each sample\n",
    "mean_lengths_jk = np.mean(np.array(mean_lengths))\n",
    "print(\"Jackknife estimate of the mean = {}\".format(mean_lengths_jk))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Estimate the median length of the wrenches along with a 95% CI."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Jackknife 95% CI lower = 9.138592415216381, upper = 10.754868124783625\n"
     ]
    }
   ],
   "source": [
    "# Leave one observation out to get the jackknife sample and store the median length\n",
    "median_lengths = []\n",
    "for i in range(n):\n",
    "    jk_sample = wrench_lengths[index != i]\n",
    "    median_lengths.append(np.median(jk_sample))\n",
    "\n",
    "median_lengths = np.array(median_lengths)\n",
    "\n",
    "# Calculate jackknife estimate and it's variance\n",
    "jk_median_length = median_lengths.mean()\n",
    "jk_var = (n-1)*np.var(median_lengths)\n",
    "\n",
    "# Assuming normality, calculate lower and upper 95% confidence intervals\n",
    "jk_lower_ci = jk_median_length - (1.96 * np.sqrt(jk_var)) \n",
    "jk_upper_ci = jk_median_length + (1.96 * np.sqrt(jk_var))\n",
    "print(\"Jackknife 95% CI lower = {}, upper = {}\".format(jk_lower_ci, jk_upper_ci))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Permutation Testing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the next few exercises, we will run a significance test using permutation testing. As discussed in the video, we want to see if there's any difference in the donations generated by the two designs - A and B. Suppose that you have been running both the versions for a few days and have generated 500 donations on A and 700 donations on B, stored in the variables donations_A and donations_B.\n",
    "\n",
    "We first need to generate a null distribution for the difference in means. We will achieve this by generating multiple permutations of the dataset and calculating the difference in means for each case.\n",
    "\n",
    "First, let's generate one permutation and calculate the difference in means for the permuted dataset.\n",
    "\n",
    "\n",
    "We want to test the hypothesis that there is a difference in the average donations received from A and B. Previously, you learned how to generate one permutation of the data. Now, we will generate a null distribution of the difference in means and then calculate the p-value.\n",
    "\n",
    "For the null distribution, we first generate multiple permuted datasets and store the difference in means for each case. We then calculate the test statistic as the difference in means with the original dataset. Finally, we calculate the p-value as twice the fraction of cases where the difference is greater than or equal to the absolute value of the test statistic (2-sided hypothesis). A p-value of less than say 0.05 could then determine statistical significance.\n",
    "\n",
    "\n",
    "Suppose that you're interested in understanding the distribution of the donations received from websites A and B. For this, you want to see if there's a statistically significant difference in the median and the 80th percentile of the donations. Permutation testing gives you a wonderfully flexible framework for attacking such problems"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "donations_A = pd.read_csv('donations_A.csv').to_numpy().flatten()\n",
    "donations_B = pd.read_csv('donations_B.csv').to_numpy().flatten()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 7.15363286  2.0224049   1.54370448  4.80860209  7.62642561  3.30058521\n",
      " 23.7058924   6.92785364  3.93432116  2.98664221]\n"
     ]
    }
   ],
   "source": [
    "print(donations_A[:10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Difference in the permuted mean values = -0.06491529406177321.\n"
     ]
    }
   ],
   "source": [
    "# Concatenate the two arrays donations_A and donations_B into data\n",
    "data = np.concatenate([donations_A, donations_B])\n",
    "\n",
    "# Get a single permutation of the concatenated length\n",
    "perm = np.random.permutation(len(donations_A) + len(donations_B))\n",
    "\n",
    "# Calculate the permutated datasets and difference in means\n",
    "permuted_A = data[perm[:len(donations_A)]]\n",
    "permuted_B = data[perm[len(donations_A):]]\n",
    "diff_in_means = permuted_A.mean() - permuted_B.mean()\n",
    "print(\"Difference in the permuted mean values = {}.\".format(diff_in_means))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "p-value = 0.0\n"
     ]
    }
   ],
   "source": [
    "reps = 100\n",
    "\n",
    "# Generate permutations equal to the number of repetitions\n",
    "perm = np.array([np.random.permutation(len(donations_A) + len(donations_B)) for i in range(reps)])\n",
    "permuted_A_datasets = data[perm[:, :len(donations_A)]]\n",
    "permuted_B_datasets = data[perm[:, len(donations_A):]]\n",
    "\n",
    "# Calculate the difference in means for each of the datasets\n",
    "samples = permuted_A_datasets.mean(axis=1) - permuted_B_datasets.mean(axis=1)\n",
    "\n",
    "# Calculate the test statistic and p-value (2 sided test)\n",
    "test_stat = donations_A.mean() - donations_B.mean()\n",
    "p_val = 2 * (np.sum(samples >= np.abs(test_stat)) / reps)\n",
    "print(\"p-value = {}\".format(p_val))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "80th Percentile: test statistic = 1.6951624520000035, p-value = 0.02\n",
      "Median: test statistic = 0.6434965699999999, p-value = 0.04\n"
     ]
    }
   ],
   "source": [
    "# Calculate the difference in 80th percentile between permuted samples-A and permuted samples-B\n",
    "# Calculate the difference in median between permuted samples-A and permuted samples-B\n",
    "samples_percentile = np.percentile(permuted_A_datasets, 80, axis=1) - np.percentile(permuted_B_datasets, 80, axis=1)\n",
    "samples_median = np.median(permuted_A_datasets, axis=1) - np.median(permuted_B_datasets, axis=1)\n",
    "\n",
    "# Calculate the test statistic from the original dataset and corresponding p-values\n",
    "test_stat_percentile = np.percentile(donations_A, 80) - np.percentile(donations_B, 80)\n",
    "test_stat_median = np.median(donations_A) - np.median(donations_B)\n",
    "\n",
    "p_val_percentile = 2 * (np.sum(samples_percentile >= np.abs(test_stat_percentile)) / reps)\n",
    "p_val_median = 2 * (np.sum(samples_median >= np.abs(test_stat_median)) / reps)\n",
    "\n",
    "print(\"80th Percentile: test statistic = {}, p-value = {}\".format(test_stat_percentile, p_val_percentile))\n",
    "print(\"Median: test statistic = {}, p-value = {}\".format(test_stat_median, p_val_median))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Modeling Corn Production\n",
    "\n",
    "Suppose that you manage a small corn farm and are interested in optimizing your costs. In this exercise, we will model the production of corn.\n",
    "\n",
    "For simplicity, let's assume that corn production depends on only two factors: rain, which you don't control, and cost, which you control. Rain is normally distributed with mean 50 and standard deviation 15. For now, let's fix cost at 5,000. Corn produced in any season is a Poisson random variable while the average corn production is governed by the equation:\n",
    "\n",
    "`100 * (cost ** 0.1) * (rain ** 0.2)`\n",
    "\n",
    "Let's model this production function and simulate one outcome."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Simulated Corn Production = 455\n"
     ]
    }
   ],
   "source": [
    "# Initialize variables\n",
    "cost = 5000\n",
    "rain = np.random.normal(loc=50, scale=15)\n",
    "\n",
    "# Corn Production Model\n",
    "def corn_produced(rain, cost):\n",
    "    mean_corn = 100 * (cost ** 0.1) * (rain ** 0.2)\n",
    "    corn = np.random.poisson(lam=mean_corn)\n",
    "    return corn\n",
    "\n",
    "# Simulate and print corn production\n",
    "corn_result = corn_produced(rain, cost)\n",
    "print(\"Simulated Corn Production = {}\".format(corn_result))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Modeling Profits**\n",
    "\n",
    "For a small farm, you typically have no control over the price or demand for corn. Suppose that price is normally distributed with mean 40 and standard deviation 10. You are given a function `corn_demanded()`, which takes the price and determines the demand for corn. This is reasonable because demand is usually determined by the market and is not in your control.\n",
    "\n",
    "In this exercise, you will work on a function to calculate the profit by pulling together all the other simulated variables. The only input to this function will be the cost. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Simulated profit = 14159.188144201802\n"
     ]
    }
   ],
   "source": [
    "def corn_demanded(price):\n",
    "    mean_corn = 1000 - 8 * price\n",
    "    corn = np.random.poisson(abs(mean_corn))\n",
    "    return corn\n",
    "\n",
    "# Function to calculate profits\n",
    "def profits(cost):\n",
    "    rain = np.random.normal(50, 15)\n",
    "    price = np.random.normal(40, 10)\n",
    "    supply = corn_produced(rain, cost)\n",
    "    demand = corn_demanded(price)\n",
    "    equil_short = supply <= demand\n",
    "    if equil_short ==True:\n",
    "        tmp = (supply * price) - cost\n",
    "        return tmp\n",
    "    else: \n",
    "        tmp2 = (demand * price) - cost\n",
    "        return tmp2\n",
    "    \n",
    "result = profits(cost)\n",
    "print(\"Simulated profit = {}\".format(result))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Optimizing Costs**\n",
    "\n",
    "We are interested in maximizing average profits. However, our profits depend on a number of factors, but we only control cost. Thus, we can simulate the uncertainty in the other factors and vary cost to see how our profits are impacted.\n",
    "\n",
    "Since you manage the small corn farm, you have the ability to choose your cost - from \\\\$100 to \\\\$5,000. You want to choose the cost that gives you the maximum average profit. In this exercise, we will simulate multiple outcomes for each cost level and calculate an average. We will then choose the cost that gives us the maximum mean profit. Upon completion, you will have a framework for selecting optimal inputs for business decisions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
